\chapter{Εισαγωγή}

Η ραγδαία εξέλιξη του Παγκόσμιου Ιστού τα τελευταία χρόνια κατέστησε το διαδίκτυο
προσβάσιμο σε εκατομμύρια χρήστες, επιτρέποντας με αυτό τον τρόπο όχι μόνο να
έχουν πρόσβαση σε περισσότερη πληροφορία παγκόσμιων ειδήσεων, αλλά να μπορούν
να ενημερώνονται και πιο γρήγορα. 
Υπάρχουν αρκετοί παράγοντες που συνετέλεσαν στην επιτυχία αυτή του
διαδικτύου, όπως, για παράδειγμα, το μειωμένο κόστος της διανομής και της
πρόσβασης στις ειδήσεις, η διαθεσιμότητα του διαδικτύου σε μια πληθώρα από
πλατφόρμες περιηγητών, η παγκόσμια αποστολή και κατανάλωση πληροφορίας, ο
μικρός χρόνος για τη δημοσίευση ειδήσεων κλπ. 

\par Λόγω της μεγάλης ποσότητας ειδήσεων που δημοσιεύονται κάθε μέρα, 
είναι δύσκολο να βρει κανείς νέες ειδήσεις που τον ενδιαφέρουν. 
Μια λύση σε αυτό το πρόβλημα είναι τα “Συστήματα Συστάσεων” {\en {(Recommender Systems)}}, 
τα οποία χρησιμοποιούν αλγόριθμους συσχέτισης, οι οποίοι, με βάση διαφόρων ειδών
πληροφορίες για τους χρήστες, επιλέγουν και προτείνουν σε αυτούς συγκεκριμένα
προϊόντα ή υπηρεσίες, ανάλογα με τις προτιμήσεις τους.

\newpage

\section{Σκοπός και Διάρθρωση της Διπλωματικής Εργασίας}
% Κλιμακωτό δύο-επιπέδων Σύστημα Συστάσεων Διαδικτυακών Εγγράφων Ειδήσεων
Η παρούσα διπλωματική εργασία επικεντρώνεται στο πεδίο των Συστημάτων Συστάσεων
και στο πλαίσιό της σχεδιάστηκε και υλοποιήθηκε
ένα σύστημα συστάσεων ειδησεογραφικού περιεχομένου που προτείνει άρθρα ειδήσεων σε μεμονωμένους χρήστες. \\

Η εργασία είναι οργανωμένη σε έξι κεφάλαια: \\

\par Στο κεφάλαιο 1 παρουσιάζονται κάποιες θεωρητικές έννοιες που σχετίζονται με την Τεχνητή Νοημοσύνη (ΤΝ), 
εισάγεται ο ορισμός της ΤΝ όπως έχει διαμορφωθεί μέχρι σήμερα και εξηγείται λεπτομερώς τι είναι η ΤΝ. 
Στη συνέχεια, δίνονται ιστορικά στοιχεία που αφορούν στη δημιουργία και εξέλιξή της μέσα στο χρόνο, 
καθώς, επίσης, αναλύονται τομείς στους οποίους αυτή χρησιμοποιείται, 
δίνοντας έμφαση στο πώς έχει συμβάλει η ΤΝ στον τομέα της ειδησεογραφικής ενημέρωσης.
Τέλος, μελετάμε τον ορισμό της Επεξεργασίας Φυσικής Γλώσσας, 
παρουσιάζουμε τα σημαντικότερα επιστημονικά πεδία έρευνας πάνω σε αυτή 
και δίνουμε το θεωρητικό υπόβαθρο της Ανάλυσης Φυσικής Γλώσσας με χρήση Μοντέλων Θεμάτων. \\

\par Στο κεφάλαιο 2 γίνεται παρουσίαση του Συστήματος Συστάσεων Διαδικτυακών Εγγράφων Ειδήσεων που αναπτύξαμε, 
αναλύεται ο σκοπός του, περιγράφεται η αρχιτεκτονική του, παρουσιάζοντας και αναλύοντας τα υποσυστήματά του. 
Τέλος, αναλύεται ο αλγόριθμος που εκτελεί για να παράγει αποτελέσματα. \\

\par Στο κεφάλαιο 3 αναφερόμαστε διεξοδικά στα προγραμματιστικά εργαλεία και τις τεχνολογίες που χρησιμοποιήθηκαν 
τόσο για την επεξεργασία φυσικής γλώσσας όσο και για την υλοποίηση της εφαρμογής. \\

\par Στο κεφάλαιο 4 παρουσιάζουμε την διεπαφή χρήστη καθώς και μερικά παραδείγματα χρήσης της εφαρμογής. \\

\par Στο κεφάλαιο 5 περιλαμβάνεται η πειραματική εφαρμογή του συστήματός μας. 
Παρουσιάζονται εκτενώς τα αποτελέσματα των πειραμάτων μας καθώς και η αξιολόγηση του συστήματος. \\

\par Τέλος, στο κεφάλαιο 6 δίνεται η συνεισφορά αυτής της διπλωματικής εργασίας 
μέσω των συμπερασμάτων που προκύπτουν, καθώς και κατευθύνσεις για πιθανές μελλοντικές επεκτάσεις.

\section{Ορισμός της Τεχνητής Νοημοσύνης}

\epigraph{{``Ονομάζουμε το είδος μας {\en {homo sapiens}} - άνθρωπος ο σοφός - επειδή οι νοητικές μας ικανότητες
είναι πολύ σημαντικές για μας. Για χιλιάδες χρόνια προσπαθούμε να κατανοήσουμε το πώς σκεπτόμαστε, 
δηλαδή, πώς μια χούφτα ύλης μπορεί να αντιλαμβάνεται, να κατανοεί, να προβλέπει και να χειρίζεται 
έναν κόσμο πολύ μεγαλύτερο και πολύ πιο πολύπλοκο από τον εαυτό της. Το πεδίο της Τεχνητής Νοημοσύνης 
πηγαίνει ακόμα πιο πέρα: Επιχειρεί όχι μόνο να κατανοήσει αλλά και να κατασκευάσει νοήμονες οντότητες."}}
{--- {\en {\textup{Russell and Norvig}, Artificial Intelligence: A modern approach}} \cite{Stu05}} 
%{Snowball}

Για  να  μπορέσουμε  να  αντιληφθούμε  καλύτερα  το  επιστημονικό  πεδίο  της Τεχνητής Νοημοσύνης, 
θα ήταν χρήσιμο να προσεγγίσουμε αρχικά την έννοια της ανθρώπινης νοημοσύνης. \\

Ο {\en {Howard Gardner}} στο βιβλίο του {\en {“Frames of mind: The theory of multiple Intelligences”}}(1983), 
διακρίνει σε κάθε άνθρωπο οχτώ  διαφορετικούς τύπους  νοημοσύνης (Γλωσσική,  Λογική/Μαθηματική,  Μουσική, 
Χωρική, Σωματική, Διαπροσωπική, Ενδοπροσωπική, Φυσιοκρατική), 
όπου αν και είναι  ευδιάκριτοι  μέσα  στον  ανθρώπινο  εγκέφαλο,
στην  πραγματικότητα χρησιμοποιείται  ένα  μίγμα  από  αυτούς. \\

Επίσης,  ο {\en {Douglas Hofstadter}} προτείνει  ότι νοημοσύνη είναι να ανταποκρίνεσαι σε καταστάσεις με 
ελαστικότητα (αποφυγή μηχανικής συμπεριφοράς), να μπορείς να κατανοείς τα ασαφή ή αντιφατικά μηνύματα από τα 
συμφραζόμενα, να μπορείς να αναγνωρίζεις και να ιεραρχείς τις καταστάσεις με βάση τη σπουδαιότητά τους, 
ενώ υποστηρίζει ότι η ανθρώπινη νοημοσύνη θα πρέπει να χαρακτηρίζεται από την ικανότητα 
να βρίσκεις ομοιότητες μεταξύ καταστάσεων που μοιάζουν διαφορετικές, 
αλλά και να μπορείς να βρίσκεις διαφορές σε καταστάσεις που φαίνονται παρόμοιες. \\

Η δοκιμασία {\en {Turing (Turing test)}}, η οποία προτάθηκε από τον {\en {Alan Turing}} (1950), σχεδιάστηκε 
για να παρέχει έναν ικανοποιητικό λειτουργικό ορισμό της νοημοσύνης. Αντί να προτείνει μια 
εκτεταμένη και ενδεχομένως αντιφατική λίστα γνωρισμάτων που απαιτούνται για τη νοημοσύνη, 
ο {\en {Turing}} πρότεινε μια δοκιμασία που βασιζόταν στην αδυναμία να γίνει διάκριση 
από τις αναμφίβολα νοήμονες οντότητες — τους ανθρώπους. O φημισμένος Άγγλος μαθηματικός έθετε το ερώτημα: 
«Μπορούν οι μηχανές να σκεφτούν;». Ο υπολογιστής περνά τη δοκιμασία αν ένας άνθρωπος εξεταστής, 
αφού θέσει μερικές γραπτές ερωτήσεις, δεν μπορεί να συμπεράνει αν οι 
γραπτές απαντήσεις προέρχονται από άνθρωπο ή όχι. 
Tότε η μηχανή χαρακτηρίζεται ως ευφυής. \cite{Stu05} \\

Μετά από αρκετούς ορισμούς και φιλοσοφικές προσεγγίσεις της Τεχνητής Νοημοσύνης, 
οι επιστήμονες φαίνεται να έχουν κατασταλάξει στον παρακάτω γενικό ορισμό: \\

{\textit{“Τεχνητή  Νοημοσύνη (ΤΝ) είναι ο τομέας της επιστήμης των υπολογιστών που 
ασχολείται με τη σχεδίαση και την υλοποίηση ευφυών (νοημόνων) υπολογιστικών συστημάτων
τα οποία είναι ικανά να μιμηθούν τις ανθρώπινες γνωστικές ικανότητες, εμφανίζοντας 
χαρακτηριστικά που αποδίδουμε συνήθως σε ανθρώπινη συμπεριφορά, όπως η επίλυση προβλημάτων, η 
αντίληψη μέσω της όρασης, η μάθηση, η εξαγωγή συμπερασμάτων, η κατανόησης της 
φυσικής γλώσσας κλπ”.}} \\

Η ΤΝ αποτελεί σημείο τομής μεταξύ πολλαπλών επιστημών όπως της πληροφορικής, 
της ψυχολογίας, της φιλοσοφίας, της νευρολογίας, της γλωσσολογίας και της επιστήμης μηχανικών, 
με στόχο τη σύνθεση ευφυούς συμπεριφοράς, με στοιχεία συλλογιστικής, μάθησης, προσαρμογής στο περιβάλλον, 
εξαγωγής συμπερασμάτων, κατανόησης από συμφραζόμενα και επίλυσης προβλημάτων, 
ενώ συνήθως εφαρμόζεται σε μηχανές ή υπολογιστές ειδικής κατασκευής. \\

\par Παρακάτω παρουσιάζονται οι τέσσερις μεγάλες κατηγορίες στις οποίες ταξινομούνται 
οι ορισμοί της ΤΝ. Ιστορικά, έχουν ακολουθηθεί και οι τέσσερις προσεγγίσεις.
Όπως θα περίμενε κανείς, υπάρχει κάποια διένεξη ανάμεσα στις προσεγγίσεις που εστιάζονται στον άνθρωπο και 
τις προσεγγίσεις που εστιάζονται στην ορθολογικότητα. Μια ανθρωποκεντρική προσέγγιση θα 
πρέπει να είναι εμπειρική επιστήμη, με υποθέσεις και με πειραματική επιβεβαίωση. 
Μια ορθολογιστική {\en {(rationalist)}} προσέγγιση περιλαμβάνει ένα συνδυασμό μαθηματικών και τεχνολογίας. 
\cite{Stu05} \\

\begin{tabularx}{400pt}{X|X}
\centering
\textbf{ΣΥΣΤΗΜΑΤΑ ΠΟΥ ΣΚΕΦΤΟΝΤΑΙ ΣΑΝ ΤΟΝ ΑΝΘΡΩΠΟ} 
& 
\textbf{ΣΥΣΤΗΜΑΤΑ ΠΟΥ ΣΚΕΦΤΟΝΤΑΙ ΟΡΘΟΛΟΓΙΚΑ} \\
\hline
“Η συναρπαστική νέα προσπάθεια για να κάνουμε τους υπολογιστές να σκέπτονται...  
μηχανές με νόηση, με την πλήρη και κυριολεκτική έννοια.” {\en {(Haugeland, 1985)}} 
\newline
\par “Η αυτοματοποίηση των δραστηριοτήτων  
που  συσχετίζουμε  με  την  ανθρώπινη  σκέψη,  
όπως η λήψη αποφάσεων, η επίλυση προβλημάτων, η μάθηση...” {\en {(Bellman, 1978)}} 
& “Η μελέτη των νοητικών ικανοτήτων με τη χρήση υπολογιστικών μοντέλων” {\en {(Craniak}} και {\en {McDermott, 1985)}} 
\newline
\par “Η μελέτη των υπολογιστικών εργασιών που μας δίνουν τη δυνατότητα να αντιλαμβανόμαστε, 
να συλλογιζόμαστε και να ενεργούμε” {\en {(Winston, 1992)}} \\
\hline
\centering
\textbf{ΣΥΣΤΗΜΑΤΑ ΠΟΥ ΕΝΕΡΓΟΥΝ ΣΑΝ ΤΟΝ ΑΝΘΡΩΠΟ} 
& 
\textbf{ΣΥΣΤΗΜΑΤΑ ΠΟΥ ΕΝΕΡΓΟΥΝ ΟΡΘΟΛΟΓΙΚΑ} \\
\hline
“Η τέχνη της δημιουργίας μηχανών που πραγματοποιούν λειτουργίες 
οι οποίες απαιτούν νοημοσύνη όταν πραγματοποιούνται από ανθρώπους” 
{\en {(Kuzweil, 1990)}}
\newline
\par “Η μελέτη του πώς μπορούμε να κάνουμε τους υπολογιστές να κάνουν πράγματα 
στα οποία, προς το παρόν, οι άνθρωποι είναι καλύτεροι”
{\en {(Rich}} και {\en {Knight, 1991)}}
& “Υπολογιστική νοημοσύνη είναι η μελέτη της σχεδίασης ευφυών πρακτόρων”
{\en {(Poole, 1998)}}
\newline
\par “Η τεχνητή νοημοσύνη ασχολείται με την ευφυή συμπεριφορά 
των τεχνουργημάτων” {\en {(Nilsson, 1998)}}
\end{tabularx}
\captionof{table}{\textbf{Ορισμοί Τεχνητής Νοημοσύνης}} 

\bigskip

\newpage
\section{Ιστορία, Εξέλιξη και Τομείς εφαρμογών Τεχνητής Νοημοσύνης}

Η Τεχνητή Νοημοσύνη (ΤΝ) έχει ήδη συμπληρώσει περισσότερο από μισό αιώνα ύπαρξης. 
Τυπικά ξεκίνησε το 1956 με τη συνάντηση επιφανών επιστημόνων, 
όπως οι {\en {Jogn McCarthy, Marvin Minsky}} και {\en {Claude Shannon}}.
Η ιστορία και η εξέλιξη της ΤΝ φαίνεται να έχει επηρεαστεί από διάφορους επιστημονικούς κλάδους, 
όπως τα Μαθηματικά, η Φιλοσοφία και η Ιατρική/Νευροεπιστήμες.\\

%\textbf{Φιλοσοφία.} 
Οι αρχές της ΤΝ τέθηκαν στην Αρχαία Ελλάδα όταν ο Αριστοτέλης 
διατύπωσε πρώτος ένα ακριβές σύνολο νόμων που διέπουν το ορθολογικό μέρος της νόησης. 
Σε μία προσπάθεια να οριοθετήσει την “ορθή σκέψη”, δηλαδή τη διαδικασία συλλογισμού, 
ανέπτυξε ένα άτυπο σύστημα συλλογισμών για τη σωστή συλλογιστική, 
οι οποίοι θεωρητικά επέτρεπαν να παράγει κανείς συμπεράσματα 
μηχανικά με δεδομένες κάποιες αρχικές υποθέσεις. \\

%\textbf{Μαθηματικά.} 
Αν και η ιδέα της τυπικής λογικής συναντάται από τον καιρό των αρχαίων Ελλήνων φιλοσόφων, 
η μαθηματική της ανάπτυξη ξεκίνησε ουσιαστικά τον 19ο αιώνα με την εργασία του {\en {George Boole}}, 
ο οποίος επεξεργάστηκε τις λεπτομέρειες της προτασιακής λογικής ή λογικής {\en {Boole}}. 
Το 1879, ο {\en {Gottlob Frege}} επέκτεινε τη λογική του {\en {Boole}} 
ώστε να συμπεριλάβει αντικείμενα και σχέσεις, θέτοντας τις βάσεις του κατηγορηματικού λογισμού.
Η μαθηματική επιστήμη προκαλείται να δώσει λύσεις για έννοιες όπως η λογική, ο υπολογισμός και η πιθανότητα. 
Ο {\en {Thomas Bayes}} πρότεινε ένα κανόνα για τον υπολογισμό της πιθανότητας, 
ο οποίος ονομάστηκε “ανάλυση {\en {Bayes}}” και αποτελεί μέχρι σήμερα την βάση των συστημάτων αβέβαιης λογικής.\\

%\textbf{Ιατρική/Νευροεπιστήμες.}
Μια σημαντική πρώτη εργασία πάνω στο θέμα δημιουργήθηκε από τους {\en {Warren McCulloch}} και {\en {Walter Pitts}}. 
Αυτή είχε σαν στόχο να συσχετίζει βιολογικούς νευρώνες του εγκεφάλου με απλά υπολογιστικά στοιχεία. 
Το συμπέρασμα αυτού ήταν μια πρόταση για επικοινωνία μεταξύ βιολογικών νευρώνων 
και υπολογιστικών στοιχείων που συνέθεταν ένα νευρωνικό δίκτυο με την ικανότητα να μαθαίνει και να κάνει υπολογισμούς. 
Το πρώτο νευρωνικό δίκτυο δημιουργήθηκε το 1951 από δυο φοιτητές του μαθηματικού τμήματος του {\en {Princeton,
Marvin Minksy}} και {\en {Dean Edmonds}}. 
Αυτό ονομάστηκε {\en {SNARC}} και αποτελούνταν από 40 νευρώνες, 3000 λυχνίες και άλλα ηλεκτρονικά εξαρτήματα.\\

Στο συνέδριο που διοργανώθηκε το 1956 στο {\en {Dartmouth}} της
Μασαχουσέτης από τους {\en {John McCarthy, Marvin Minksy, Claude Shannon}} 
και {\en {Nathaniel Rochester}} παρουσιάστηκε από τους ερευνητές {\en {Allen Newell}} και
{\en {Herbert Simon}} το {\en {Logic Theorist}}, ένα πρόγραμμα συλλογισμού το οποίο
μπορούσε να αποδεικνύει τα περισσότερα από τα θεωρήματα των {\en {Russell}} και {\en {Whitehead}}. 
Στο ίδιο συνέδριο προτάθηκε και από τον {\en {McCarthy}} το όνομα Τεχνητή Νοημοσύνη, το οποίο έγινε αποδεκτό. \\

Το 1958 δημιουργήθηκε η συναρτησιακή γλώσσα {\en {Lisp}}. 
Η γλώσσα αυτή έγινε ταυτόσημο της ΤΝ για αρκετά μεγάλο χρονικό διάστημα. 
Την ίδια χρονιά ο {\en {McCarthy}} πρότεινε το {\en {Advice Taker}}, ένα πρόγραμμα το οποίο χρησιμοποιούσε
γνώση για την επίλυση καθημερινών προβλημάτων. 
Η υλοποίησή του έγινε το 1963 από τον ίδιο.
Λίγο αργότερα, στο {\en {Stanford Research Institute}} δημιουργήθηκε το πρώτο ρομπότ με το όνομα {\en {Shakey}}. \\

Η επόμενη δεκαετία δεν ήταν τόσο ελπιδοφόρα όσο η πρώτη. Η ΤΝ κατηγορήθηκε ως ένα μέσο επίλυσης απλών προβλημάτων
{\en {(toy problems)}}. Έτσι, το 1973 η Βρετανική κυβέρνηση διέκοψε την υποστήριξη της έρευνας στην ΤΝ. \\

Την δεκαετία που ακολούθησε αναπτύχθηκαν “έμπειρα συστήματα”, τα οποία περιείχαν αρκετή γνώση του προβλήματος που αντιμετώπιζαν. 
Την ίδια δεκαετεία αναπτύχθηκε η γλώσσα προγραμματισμού {\en {Prolog}}, η οποία βασιζόταν στην λογική. \\

Ένα από τα συστήματα που αναπτύχθηκαν κατά την πορεία της ΤΝ μέσα στις δεκαετίες ήταν και το {\en {DENDRAL}}. 
Αυτό περιείχε σημαντική ποσότητα γνώσης η οποία εκφραζόταν με την μορφή κανόνων. 
Ένα άλλο παρόμοιο σύστημα ήταν το {\en {MYCIN}}, το οποίο περιελάμβανε 450 κανόνες 
και ο σκοπός του ήταν η διάγνωση μολύνσεων στο αίμα.
Η γνώση του συγκεκριμένου συστήματος δεν προέκυψε από κάποιο μοντέλο όπως στο {\en {DENDRAL}}, 
αλλά από συνεντεύξεις σε γιατρούς. 
Αξίζει να σημειωθεί οτι το σύστημα αυτό εισήγαγε την έννοια της αβεβαιότητας.
Ένα ακόμα αντιπροσωπευτικό σύστημα ήταν και το {\en {PROSPECTOR}}, στον τομέα της γεωλογίας, 
αφού έδινε πληροφορίες για τοποθεσίες εξόρυξης κοιτασμάτων.
Στον τομέα της κατανόησης της φυσικής γλώσσας ήταν το {\en {SHRDLU}}, το οποίο
περιοριζόταν σε προβλήματα μετακίνησης αντικειμνένων και το {\en {LUNAR}}, το οποίο
χρησιμοποιήθηκε σε πραγματικές εφαρμογές και δεχόταν ερωτήσεις για τα
πετρώματα που έφερναν τα διαστημόπλοια {\en {APOLLO}} στην γη από τη σελήνη. 
Το πρώτο επιτυχημένο εμπορικό σύστημα ήταν το {\en {R1/XCON}}, 
του οποίου η χρήση ήταν η διαμόρφωση των παραγγελιών της εταιρίας {\en {Digital Equipments
Corporation}} με βάση τις ανάγκες των πελατών και τα διαθέσιμα αποθέματα εξαρτημάτων. 
Κατά τα μέσα της δεκαετίας του '80, τα νευρωνικά δίκτυα ήρθαν πάλι στο προσκήνιο. \\

Αν τώρα θελήσουμε να δούμε την εξέλιξη της ΤΝ χρονολογικά, 
θα δούμε ότι πολλοί συγγραφείς διακρίνουν τέσσερις περιόδους: 
την προϊστορική, την κλασική, τη ρομαντική και την μοντέρνα. Στην
προϊστορική περίοδο, η ΤΝ συναντάται σαν αντικείμενο μόνο σε διηγήματα
επιστημονικής φαντασίας. Την κλασική περίοδο, στην οποία τα συστήματα που
αναπτύχθηκαν έλυναν γρίφους και έπαιζαν παιχνίδια. Κατά την ρομαντική
περίοδο, η ΤΝ επικεντρώνεται κυρίως στην ανάπτυξη συστημάτων για
κατανόηση ιστοριών και διαλόγων σε φυσική γλώσσα. Η μοντέρνα περίοδος 
βασίζεται στην δημιουργία συστημάτων που έχουν ως σκοπό την εμπορική
εκμετάλευση των αποτελεσμάτων της έρευνας της ΤΝ.

Αυτή την εποχή βιώνουμε τη μετα-μοντέρνα περίοδο, όπου η TN
καλείται να παίξει σημαντικό ρόλο σε ένα πληροφοριακό περιβάλλον  
όπου τα κύρια χαρακτηριστικά του είναι η εξάπλωση του διαδικτύου και η διείσδυση των 
υπολογιστικών  συστημάτων  σε  κάθε  είδους  συσκευές  ευρείας  και  καθημερινής χρήσης. \\

Τα τελευταία χρόνια, η ανάπτυξη της ΤΝ είναι αλματώδης και έτσι σήμερα υπάρχουν 
εφαρμογές της όπως η ρομποτική (συστήματα ρομποτικής χειρουργικής), η μηχανική όραση και η μηχανική μάθηση. 
Υπάρχουν πολλά ευφυή προγράμματα τα οποία βοηθούν τον χρήστη να αναζητά
πληροφορίες στο διαδίκτυο, να στέλνει {\en {email}} και άλλα. 
Άλλη εφαρμογή είναι τα συστήματα αναγνώρισης φωνής, όπως το σύστημα {\en {PEGASUS}}
που κάνει αεροπορικές κρατήσεις και προτείνει τις βέλτιστες πτήσεις για κάθε
πελάτη. Υπάρχουν, επίσης, έμπειρα συστήματα πραγματικού χρόνου τα οποία
επεξεργάζονται δεδομένα τα οποία στέλνονται από διαστημόπλοια. 
Τέλος, υπάρχουν ευφυή συστήματα τα οποία οδηγούν οχήματα σε πραγματικές συνθήκες 
χρησιμοποιώντας κάμερες και αποστασιόμετρα. \\

Οι νευροεπιστήμες που ασχολούνται με την μελέτη του νευρικού συστήματος και ιδιαίτερα του εγκεφάλου,
καθώς και η ιατρική, αποτελούν επιστήμες που τα τελευταία χρόνια χρησιμοποιούν συστήματα ΤΝ. 
Οι περιοχές όπου βρίσκουν εφαρμογή τέτοια συστήματα είναι τα πεδία της πρόληψης, 
της διάγνωσης και της θεραπείας διαφόρων ασθενειών. 
Χρησιμοποιώντας κυρίως ασαφή συστήματα, η ΤΝ προκαλείται να 
απαντήσει σε σύγχρονα προβλήματα, τα οποία σχετίζονται με την υγεία, 
το καλύτερο βιωτικό επίπεδο και της βέλτιστη θεραπευτική επιλογή. \\

Άλλες επιστήμες στις οποίες η ΤΝ βρίσκει εφαρμογή αλλά και επηρεάστηκε από αυτές είναι η ψυχολογία, η πληροφορική και η γλωσσολογία. \\

Τα υπολογιστικά συστήματα πλέον εξελίσσονται με αλματώδη ρυθμό. 
Έτσι, λοιπόν, δημιουργούνται νέες απαιτήσειςγια την επίλυση προβλημάτων.
Η ΤΝ ανεβάζει διαρκώς τον πήχη και στοχεύει στη δημιουργία συστημάτων
τα οποία να εξαρτώνται ελάχιστα από τον κατασκευαστή τους 
και περισσότερο από την ικανότητά τους να μαθαίνουν πώς να συμπεριφέρονται 
σε αλληλεπίδραση με το περιβάλλον τους.

%\begin{enumerate}
%\item %\cite{KokkinidisC04}. 
%\end{enumerate}
\section{Συμβολή της Τεχνητής Νοημοσύνης στον Ειδησεογραφικό Τομέα}

Το διαδίκτυο είναι μία από τις δημοφιλέστερες πλατφόρμες για τη διανομή και την ανάγνωση
ειδήσεων. Υπάρχουν αρκετοί παράγοντες που συνετέλεσαν στην επιτυχία αυτή του
διαδικτύου, όπως το μειωμένο κόστος της διανομής και της πρόσβασης στις ειδήσεις, 
η διαθεσιμότητα του διαδικτύου σε μια πληθώρα από πλατφόρμες περιηγητών, 
η παγκόσμια αποστολή και κατανάλωση πληροφορίας, ο μικρός χρόνος για τη δημοσίευση ειδήσεων κλπ. 

Δυστυχώς, η επιτυχία του διαδικτύου είναι και ένα από τα μεγαλύτερα προβλήματά του: 
η μεγάλη ποσότητα καθημερινά δημοσιευμένων ειδήσεων κάνει δύσκολη τη διαδικασία εύρεσης αυτών που
αντιστοιχούν σε συγκεκριμένα ενδιαφέροντα. Διαδικτυακές εφημερίδες παρουσιάζουν
τα τελευταία νέα στους ιστοτόπους τους σε πραγματικό χρόνο, και οι χρήστες μπορούν
να λαμβάνουν αυτόματες ειδοποιήσεις για αυτά μέσω τροφοδοσιών {\en {RSS}}. Το πρότυπο
{\en {RSS}} προέρχεται από το αγγλικό {\en {Really Simple Syndication}} και είναι βασισμένο στη
γλώσσα {\en {XML}} για την διανομή των ενημερώσεων του περιεχομένου του ιστού. Τα {\en {RSS
feeds}} προσφέρουν τη δυνατότητα στους χρήστες να λαμβάνουν νέες πληροφορίες από
διάφορες ιστοσελίδες τη στιγμή που δημοσιεύονται χωρίς να χρειάζεται να τις
επισκεφθούν. Το {\en {RSS}} είναι, δηλαδή, ένας νέος τρόπος ενημέρωσης για νέα, εξελίξεις και
γεγονότα. 

Είναι γεγονός πως το διαδίκτυο αποτελείται πλέον από δισεκατομμύρια
σελίδες οι οποίες περιέχουν τέτοιο πλούτο πληροφοριών που είναι σχεδόν αδύνατο
για τον οποιονδήποτε να μπορεί να παρακολουθεί διαρκώς ό,τι νεότερο συμβαίνει στον
κόσμο ή στο αντικείμενο που τον ενδιαφέρει. Στο πρόβλημα αυτό ήρθαν να δώσουν τη
λύση τα {\en {RSS feeds}}. Με τα {\en {feeds}} ο χρήστης μπορεί να βλέπει πότε ανανεώθηκε το
περιεχόμενο των δικτυακών τόπων που τον ενδιαφέρουν, λαμβάνοντας κατευθείαν
στον υπολογιστή του τους τίτλους των τελευταίων ειδήσεων και των άρθρων (ή ακόμα
και εικόνων ή βίντεο) αμέσως μόλις αυτά γίνουν διαθέσιμα χωρίς να είναι απαραίτητο
να επισκέπτεται καθημερινά τους αντίστοιχους δικτυακούς τόπους. Χρησιμοποιώντας
αυτό το φορμάτ, οι υπεύθυνοι του ιστού δημιουργούν επικεφαλίδες και καινούργιο
περιεχόμενο με συντετμημένο τρόπο(τροφοδοσία) και οι χρήστες μπορούν να
χρησιμοποιήσουν αναγνώστες {\en {feeds}} και συναθροιστές ειδήσεων για να συλλέξουν και
να παρακολουθήσουν τις αγαπημένες τους τροφοδοσίες από ένα κεντρικό σημείο. Τα
{\en {feeds}} γίνονται όλο και πιο δημοφιλή. Όμως, η διαρκής ροή ειδήσεων από διάφορες
πηγές ενημέρωσης δεν εξυπηρετεί το χρήστη, καθώς καθιστά αδύνατη την
παρακολούθησή τους και κρίνεται επιβεβλημένη η προσωποποίηση του
αποτελέσματος. Μια πιθανή λύση στο πρόβλημα της υπερφόρτωσης πληροφοριών με
ειδήσεις είναι η χρήση συστημάτων συστάσεων, ο σκοπός των οποίων είναι να
προτείνουν αντικείμενα που προηγουμένως ήταν άγνωστα, στην περίπτωση μας
ειδήσεις, και θα ενδιέφεραν ένα συγκεκριμένο χρήστη. Τυπικά, τέτοια συστήματα
χρησιμοποιούν προφίλ χρηστών και έχουν στόχο την σύσταση ειδήσεων που
ταιριάζουν καλύτερα στο προφίλ αυτό. 

\section{Συστήματα Συστάσεων}

Τα συστήματα συστάσεων είναι εφαρμογές λογισμικού που παρέχουν εξατομικευμένες
προστάσεις στους χρήστες σχετικά με προϊόντα ή υπηρεσίες που μπορεί να τους
ενδιαφέρουν. Προτείνουν στοιχεία σχετικά με τα ενδιαφέροντα των χρηστών βάσει
των προτιμήσεών τους, οι οποίες εκφράζονται είτε άμεσα {\en {(explicitly)}}, είτε έμμεσα {\en {(implicitly)}}.
Τα συστήματα αυτά με τη βοήθεια ειδικών αλγορίθμων επιχειρούν να προβλέψουν
ποιες υπηρεσίες είναι πιθανόν να ενδιαφέρουν περισσότερο τον χρήστη. Οι τεχνικές
που χρησιμοποιούνται λαμβάνουν ως είσοδο τα χαρακτηριστικά και τις προτιμήσεις
του χρήστη (προσωπικά στοιχεία, ιστορικό περιήγησης) της σχέσεις μεταξύ των
χρηστών και τα γνωρίσματα των προς σύσταση αντικειμένων, και υπολογίζουν το
εκτιμώμενο ενδιαφέρον του χρήστη για κάθε αντικείμενο. Στη συνέχεια, φιλτράρουν ή
ταξινομούν τα αντικείμενα με κριτήριο το εκτιμώμενο ενδιαφέρον. Τυπικά, τέτοια
συστήματα χρησιμοποιούν προφίλ χρηστών και έχουν σαν στόχο τη σύσταση στοιχείων
που ταιριάζουν περισσότερο στο προφίλ αυτό. Η δημιουργία προφίλ αποτελεί το πλέον
σημαντικό στοιχείο ενός συστήματος συστάσεων. Τα συστήματα συστάσεων
εκμεταλλεύονται τις ιδιαιτερότητες των χρηστών με σκοπό να διευκολύνουν στο να
προσδιορίζουν ακριβέστερα τις πληροφορίες ή τα προϊόντα για τα οποία
ενδιαφέρονται περισσότερο ή σχετίζονται με τις ανάγκες τους. Πιο συγκεκριμένα, ένα
σύστημα συστάσεων μπορεί να κρατάει ιστορικό από τα άρθρα που έχει διαβάσει
κάποιος χρήστης, οπότε την επόμενη φορά που θα επισκεφθεί τον ιστότοπο, το
σύστημα θα του προτείνει νέα άρθρα σύμφωνα με την θεματολογία αυτών που είχε
διαβάσει στο παρελθόν και πιθανόν να τον ενδιέφεραν. \\
Τα συστήματα συστάσεων αποτελούν ένα σημαντικό πεδίο με μεγάλο ενδιαφέρον σε
ερευνητικό επίπεδο, από την εμφάνιση των πρώτων δημοσιεύσεων για το συνεργατικό
φιλτράρισμα στα μέσα της δεκαετίας του '90. Υπάρχει μεγάλη δραστηριότητα τόσο στη
βιομηχανία όσο και στην ακαδημαϊκή κοινότητα για την ανάπτυξη νέων προσεγγίσεων κατά
την τελευταία δεκαετία. \\
Παρά το μεγάλο ενδιαφέρον των εταιρειών και το σημαντικό όγκο ερευνητικής δραστηριότητας
για τα συστήματα συστάσεων, απαιτούνται περαιτέρω βελτιώσεις, 
οι οποίες περιλαμβάνουν καλύτερες μεθόδους αναπαράστασης του προφίλ των χρηστών 
και των στοιχειών που προτείνονται, πιο εξελιγμένες μεθόδους δημιουργίας συστάσεων, 
ενσωμάτωση των διάφορων, βασισμένων στα συμφραζόμενα, πληροφοριών στη διαδικασία συστάσεων,
και ανάπτυξη πιο ευέλικτων μεθόδων, οι οποίες θα στηρίζονται σε μέτρα που
καθορίζουν αποτελεσματικότερα την παραγωγή συστάσεων.

\subsection{Κατηγορίες Συστημάτων Συστάσεων}

Τα συστήματα συστάσεων ταξινομούνται στις παρακάτω τρεις βασικές κατηγορίες ανάλογα με την προσέγγιση που εφαρμόζουν:
\begin{enumerate}
  \item Φιλτράρισμα βασισμένο στο περιεχόμενο {\en {(Content - Based Filtering)}}: 
Τα συστήματα συστάσεων που βασίζονται στο
περιεχόμενο συγκρίνουν τα ενδιαφέροντα του χρήστη, που έχουν συλλεχθεί
έμμεσα ή άμεσα, με τα χαρακτηριστικά των αντικειμένων. Το βασικό
χαρακτηριστικό της μεθόδου αυτής είναι το μέτρο ομοιότητας που δηλώνει
πόσο σχετίζεται ένα αντικείμενο με κάποιον χρήστη. Τα συστήματα προτάσεων
περιεχομένου που βασίζονται σε μοντέλα συνήθως «βλέπουν» τη δημιουργία
σύστασης σαν ένα πρόβλημα κατηγοριοποίησης διαφορετικό για κάθε χρήστη,
και μαθαίνουν έναν ταξινομητή για αυτά που αρέσουν και αυτά που δεν
αρέσουν στον χρήστη με βάση τα χαρακτηριστικά του αντικειμένου.
  \item Συνεργατικό φιλτράρισμα {\en {(Collaborative Filtering)}}: 
Χρησιμοποιεί δεδομένα σχετικά με τις προτιμήσεις
ενός συνόλου χρηστών για να προτείνει περιεχόμενο σε έναν χρήστη-στόχο με
παρόμοια ενδιαφέροντα. Συνήθως, αυτές οι μέθοδοι δεν χρησιμοποιούν
πληροφορίες που έχουν να κάνουν με το περιεχόμενο αυτό καθ' αυτό, αλλά
βασίζονται στις γνώμες των χρηστών (συνήθως, αξιολογήσεις που έχουν
συλλεχθεί άμεσα). Τα συνεργατικά συστήματα προτάσεων βάσει μνήμης
χρησιμοποιούν συνήθως ευρετικές τεχνικές, όπως ανάλυση συσχέτισης και
ομοιότητα διανυσμάτων και μπορούν να χωριστούν σε δύο διαφορετικούς
τύπους, ανάλογα με τη βάση της ομοιότητας: σε συστήματα βάσει χρήστη, όταν
ο αλγόριθμος συνίσταται στην εύρεση παρόμοιων χρηστών με τον ενεργό και σε
συστήματα βάσει αντικειμένου, όταν ο αλγόριθμος έχει να κάνει με την εύρεση
αντικειμένων παρόμοιων με αυτά που αρέσουν στον ενεργό χρήστη . Τα
συνεργατικά συστήματα προτάσεων βάσει μνήμης συνήθως χρησιμοποιούν
πιθανοτικούς ταξινομητές όπως Μπεϋζιανά δίκτυα καθώς και μοντέλα
συσταδοποίησης .
  \item Υβριδικές τεχνικές συστάσεων {\en {(Hybrid Recommendation Methods)}}: 
Τα συστήματα συστάσεων βασίζονται κυρίως σε δύο
μεθόδους: βάσει περιεχομένου και συνεργατικό φιλτράρισμα, για να
προτείνουν σε κάποιο χρήστη ένα έγγραφο. Οι μέθοδοι αυτοί εάν εφαρμοστούν
μεμονωμένα, παρουσιάζουν κάποια μειονεκτήματα και έχουν συγκεκριμένα
προβλήματα. Προκειμένου να αντιμετωπιστούν τα προβλήματα αυτά,
υιοθετούνται υβριδικές προσεγγίσεις οι οποίες συνδυάζουν και τις δύο
μεθόδους.
\end{enumerate}

\section{Επεξεργασία Φυσικής Γλώσσας}

Η Επεξεργασία της Φυσικής Γλώσσας (ΕΦΓ) {\en {(Natural Language Processing - NLP)}}
είναι ένας διεπιστημονικός κλάδος της επιστήμης της Πληροφορικής, της Τεχνητής Νοημοσύνης 
και της Υπολογιστικής Γλωσσολογίας και ασχολείται με τις αλληλεπιδράσεις μεταξύ των υπολογιστών και της ανθρώπινης (φυσικής) γλώσσας. 
Η ανάπτυξη του πεδίου αυτού ξεκίνησε σαν ένα μέρος της ΤΝ. 
Προκλήσεις στην ΕΦΓ περιλαμβάνουν την κατανόηση φυσικής γλώσσας, 
δηλαδή την προσπάθεια να καταστούν ικανοί οι υπολογιστές να εξάγουν νοήματα από ανθρώπινα ή γλωσσικά δεδομένα, 
αλλά και την παραγωγή φυσικής γλώσσας. \\

Οι βασικές τεχνικές επεξεργασίας φυσικού κειμένου βασίζονται στις γενικές γνώσεις σχετικά με τη φυσική γλώσσα. 
Χρησιμοποιούν ορισμένους απλούς ευρετικούς κανόνες οι οποίοι στηρίζονται 
στη συντακτική και σημασιολογική προσέγγιση και ανάλυση του κειμένου. 
Ορισμένες τεχνικές που αφορούν σε όλα τα πεδία εφαρμογής είναι: 
ο διαμερισμός στα συστατικά στοιχεία του κειμένου {\en {(tokenization)}}, 
η χρήση της διάταξης του κειμένου {\en {(structural data mining)}},
η απαλοιφή λέξεων που δεν φέρουν ουσιαστική πληροφορία {\en {(elimination of insignificant words)}},
η γραμματική δεικτοδότηση {\en {(PoS tagging)}}, 
η μορφολογική ανάλυση και η συντακτική ανάλυση.

\subsection{Πεδία έρευνας Επεξεργασίας Φυσικής Γλώσσας}

Στην υποενότητα αυτή παρουσιάζονται τα κυριότερα πεδία στα οποία γίνεται εκτεταμένη έρευνα της Επεξεργασίας Φυσικής Γλώσσας. 
Το κριτήριο διαχωρισμού των πεδίων αυτών είναι το γεγονός ότι για το καθένα από αυτά υπάρχει ένας επίσημα ορισμένος χώρος 
μελέτης και επίλυσης ζητημάτων, ένα καθιερωμένο μετρικό σύστημα για την αξιολόγηση των ερευνών που προκύπτουν από το
πεδίο, κάποια δεδομένα σύνολα κειμένων πάνω στα οποία κάθε πεδίο αξιολογείται και διαγωνισμοί αφιερωμένοι στο κάθε πεδίο.
\begin{itemize}
 \item Ανάλυση λόγου: Αναγνώριση της δομής του λόγου εντός των αναλυόμενων κειμένων, π.χ. την φύση των σχέσεων του λόγου μεταξύ δύο προτάσεων. 
 Επίσης, αναφέρεται στην αναγνώριση και την κατηγοριοποίηση των γλωσσικών πράξεων σε ένα μέρος του κειμένου.
 \item Αυτόματη αναγνώριση ομιλίας: Η αυτόματη μετατροπή του ανθρώπινου λόγου όπως προφέρεται σε κείμενο από τους τους υπολογιστές.
 \item Αυτόματη ερωταπόκριση: Η αναζήτηση της σωστής απάντησης σε μία δεδομένη ερώτηση, όπως διαμορφώνεται από την ανθρώπινη γλώσσα.
 \item Αυτόματη μορφολογική τεμαχιοποίηση: Η κατάτμηση των λέξεων στα μορφήματά τους,
 καθώς και η αναγνώριση και κατηγοριοποίηση αυτών των μορφημάτων. 
 Η δυσκολία του συγκεκριμένου πεδίου μελέτης εξαρτάται σε μεγάλο βαθμό 
 από την περιπλοκότητα της μορφολογίας της εκάστοτε γλώσσας υπό εξέταση.
 \item Αυτόματη περίληψη: Η παραγωγή μίας αναγνώσιμης (από τον άνθρωπο) περίληψης ενός κειμένου. 
 Συχνά χρησιμοποιείται για να παρέχει περιλήψεις σε κείμενα γνωστής διάταξης, 
 όπως οικονομικά ή πολιτικά ειδησεογραφικά άρθρα.
 \item Εξόρυξη πληροφοριών: Η ανάκτηση πληροφοριών από μη δομημένα ή ημιδομημένα δεδομένα 
 (τυπικά κείμενα γραμμένα σε φυσική γλώσσα, ιστοσελίδες κ.α.)
 \item Επίλυση σχέσεων συναναφοράς: Η αναζήτηση των λέξεων (αναφορές) 
 οι οποίες αναφέρονται στα ίδια υποκείμενα (οντότητες) σε μία δεδομένη πρόταση ή μεγαλύτερο τμήμα κειμένου. 
 Η επίλυση σχέσεων αναφοράς είναι ένα συγκεκριμένο παράδειγμα αυτού του πεδίου 
 και αναφέρεται συγκεκριμένα στην σύνδεση των αντωνυμιών με τα ουσιαστικά 
 ή τα ονόματα στα οποία αναφέρονται.
 \item Επισήμανση των μερών του λόγου: Ο αυτόματος καθορισμός των μερών του λόγου σε μία δεδομένη πρόταση 
 και η επίλυση της συντακτικής αμφισημίας.
 \item Κατανόηση του φυσικού λόγου: Η μετατροπή κομματιών κειμένου σε πιο τυπικές αναπαραστάσεις όπως σε δομές λογικής πρώτου βαθμού, 
 οι οποίες μπορούν να μεταχειριστούν ευκολότερα από τους υπολογιστές.
 \item Μηχανική μετάφραση: Η αυτόματη μετάφραση ενός κειμένου από μία ανθρώπινη γλώσσα σε μία άλλη.
 \item Οπτική αναγνώριση χαρακτήρων {\en {(Optical Character Recognition - OCR)}}: 
 Ο προσδιορισμός του αντίστοιχου κειμένου από μία δεδομένη εικόνα που αναπαριστά κάποιο τυπογραφημένο κείμενο.
 \item Παραγωγή φυσικού λόγου: Η μετατροπή των πληροφοριών από υπολογιστικές βάσεις δεδομένων σε αναγνώσιμο φυσικό λόγο.
 \item Σύνθεση ομιλίας: Η αυτόματη, τεχνητή παραγωγή του ανθρώπινου λόγου από υπολογιστές.
 \item Συντακτική ανάλυση: Ο αυτόματος καθορισμός της σύνταξης μίας δεδομένης πρότασης και η επίλυση των οποιοδήποτε συντακτικών αμφισημιών. 
 Εξαιτίας των αμφισημιών που πιθανόν να φέρει μία πρόταση, είναι δυνατόν η εν λόγω πρόταση να αναλυθεί σε παραπάνω από ένα συντακτικά δέντρα.
\end{itemize}

\subsection{Ανάλυση Φυσικής Γλώσσας με χρήση Θεματικών Μοντέλων}

Στη Μηχανική Εκμάθηση και στην Επεξεργασία Φυσικής Γλώσσας ένα μοντέλο θεμάτων
{\en {(topic model)}} είναι ένας τύπος στατιστικού μοντέλου για την ανακάλυψη θεμάτων που
υπάρχουν σε μία συλλογή κειμένων. Τα μοντέλα θεμάτων βασίζονται στην ιδέα ότι τα
κείμενα είναι μείγματα θεμάτων όπου ένα θέμα είναι μια πιθανότητα κατανομής λέξεων.
Στόχος μας είναι να βρούμε σύντομες περιγραφές των μελών της συλλογής 
που επιτρέπουν μια αποτελεσματική επεξεργασία μεγάλων συλλογών, 
διατηρώντας τις απαραίτητες στατιστικές σχέσεις που είναι χρήσιμες
για βασικές διεργασίες όπως η περίληψη κειμένου. \\

Σημαντική επεξεργασία έχει γίνει πάνω σε αυτό το πρόβλημα από ερευνητές στο
αντικείμενο του πεδίου ανάκτησης πληροφοριών {\en {(IR)(Baeza-Yates}} και {\en {Ribeiro-Neto}}, 1999).
Η βασική μεθοδολογία που προτάθηκε από τους {\en {IR}} ερευνητές για συλλογές κειμένων – μια
μεθοδολογία η οποία εφαρμόστηκε με επιτυχία στις μοντέρνες μηχανές αναζήτησης του
Διαδικτύου - μετατρέπει κάθε κείμενο σε ένα διάνυσμα πραγματικών αριθμών, καθένα από
τα οποία αντιπροσωπεύει μία αναλογία μετρήσεων. Στο δημοφιλές \textbf{{\en {tf-idf}}} σχήμα {\en {(Salton}} και
{\en {McGill}}, 1983) επιλέγεται το βασικό λεξιλόγιο των “όρων” και για κάθε
κείμενο της συλλογής σχηματίζεται μία μέτρηση από τον αριθμό των φορών που έχει
παρουσιαστεί μια λέξη. Μετά από κατάλληλη κανονικοποίηση, ο δείκτης συχνότητας
συγκρίνεται με το αντίστροφο δείκτη συχνότητας κειμένων, που μετράει τον αριθμό που
έχει βρεθεί μια λέξη σε όλη την συλλογή (γενικά σε λογαριθμική κλίμακα και μετά
μοντελοποιείται κατάλληλα). Το τελικό αποτέλεσμα είναι ένας πίνακας όρων ανά κειμένων
{\en {X}}, του οποίου οι στήλες περιέχουν τις {\en {tf-idf}} αξίες για κάθε κείμενό της. 
Έτσι, το {\en {tf-idf}} σχήμα μειώνει τα κείμενα αυθαίρετου μήκους σε φορμαρισμένου μήκους λίστες αριθμών. \\

Καθώς η {\en {tf-idf}} μείωση έχει κάποιες δελεαστικές ιδιότητες,
η προσέγγιση παρέχει επίσης μια σχετικά μικρή μείωση του μήκους περιγραφής 
και φανερώνει λίγα για την στατιστική μορφή των κειμένων. 
Για την αντιμετώπιση των παραπάνω προβλημάτων οι {\en {IR}} ερευνητές
πρότειναν πολλές άλλες τεχνικές μείωσης του πλήθους διαστάσεων, η πιο αξιοσημείωτη εκ
των οποίων είναι η \textbf{{\en {Latent Semantic Indexing (LSI)}}} {\en {(Deerwester et al., 1990))}}. H {\en {LSI}}
εφαρμόζει αποσύνθεση τιμών στον {\en {X}} πίνακα για να ορίσει έναν γραμμικό υποχώρο στον 
χώρο των {\en {tf-idf}} ιδιοτήτων, που πιάνει ένα μεγάλο μέρος της διακύμανσης της συλλογής.
Αυτή η προσέγγιση μπορεί να πετύχει μια σημαντική ελαχιστοποίηση μεγάλων συλλογών.
Επιπλέον, o {\en {Deerwester}} υποστηρίζει ότι τα παραγόμενα χαρακτηριστικά του {\en {LSI}}, που
είναι γραμμικοί συνδυασμοί των αυθεντικών {\en {tf-idf}} χαρακτηριστικών, μπορούν να πιάσουν
κάποιες πτυχές των βασικών γλωσσολογικών ιδεών όπως η συνωνυμία και η πολυσημία. \\

Ένα σημαντικό βήμα ήταν η παρουσίαση του πιθανοτικού {\en {LSI \textbf{(probabilistic LSI)}}}
μοντέλου, γνωστού επίσης και σαν Μοντέλο Συμπερασμάτων. H {\en {pLSI}} προσέγγιση
μοντελοποιεί κάθε λέξη ενός κειμένου ως ένα δείγμα ενός {\en {mixture}} μοντέλου, όπου τα
αναμεμιγμένα στοιχεία είναι τυχαίες πολυωνυμικές μεταβλητές που μπορούν να
κατανοηθούν ως παρουσιάσεις θεμάτων. Έτσι, κάθε λέξη δημιουργείται από ένα απλό θέμα,
και διαφορετικές λέξεις σε ένα κείμενο μπορεί να δημιουργηθούν από διαφορετικά θέματα.
Κάθε κείμενο απεικονίζεται ως μία λίστα αναμεμειγμένων αναλογιών για κάθε {\en {mixture}}
συστατικό και έτσι μειώνεται σε μια πιθανοτική κατανομή φορμαρισμένων συνόλων
θεμάτων. Αυτή η κατανομή είναι μια “ελαχιστοποιημένη περιγραφή” συσχετισμένη με ένα
κείμενο. \\

Αν και η δουλειά του {\en {Hoffman}} είναι ένα χρήσιμο βήμα πάνω στην θεματική
μοντελοποίηση κειμένων, δεν είναι πλήρης, γιατί δεν παρέχει κανένα πιθανοτικό μοντέλο
για την επεξεργασία σε επίπεδο κειμένων. Στο {\en {pLSI}} κάθε κείμενο παρουσιάζεται ως λίστα
αριθμών και δεν υπάρχει κανένα γενετικό πιθανοτικό μοντέλο για αυτούς τους αριθμούς.
Αυτό επιφέρει αρκετά προβλήματα: (1) ο αριθμός των παραμέτρων στο μοντέλο μεγαλώνει
γραμμικά με το μέγεθος της συλλογής, κάτι που οδηγεί σε σοβαρά προβλήματα σχετικά με
το {\en {overfitting}} και (2) δεν είναι ξεκάθαρο πως διανέμεται η κατανομή σε ένα κείμενο εκτός
του εκπαιδευτικού συνόλου. \\

Για να καταλάβετε πώς θα προχωρήσουμε πέρα από το {\en {LSI}}, ας θεωρήσουμε τις βασικές
πιθανοτικές υποθέσεις υπογραμμίζοντας την κλάση των μεθόδων μείωσης διαστάσεων που
περιέχει το {\en {LSI}} και το {\en {pLSI}}. 
Όλες αυτές οι μέθοδοι βασίζονται στην \textit{{\en {bag-of-words}}} υπόθεση – ότι η σειρά των λέξεων μπορεί να αγνοηθεί. 
Στη γλώσσα της πιθανοτικής θεωρίας αυτή είναι η υπόθεση της ανταλλαξιμότητας των λέξεων σε ένα κείμενο. 
Αυτές οι μέθοδοι υποθέτουν επίσης ότι τα κείμενα είναι ανταλλάξιμα: 
η σειρά των κείμενων σε μια συλλογή μπορεί να αλλάξει. \\

Ένα κλασσικό θεώρημα του {\en {de Finetti}} (1990) τεκμηριώνει ότι κάθε συλλογή από ανταλλάξιμες τυχαίες μεταβλητές 
έχει μια απεικόνιση σαν {\en {mixture}} κατανομή. 
Έτσι, αν επιθυμούμε να θεωρήσουμε ανταλλάξιμες απεικονίσεις κειμένων για κείμενα και λέξεις,
πρέπει να θεωρήσουμε {\en {mixture}} μοντέλα που λαμβάνουν υπόψη τους την ανταλλαξιμότητα και των λέξεων αλλά και των κειμένων. 
Αυτό οδήγησε στην δημιουργία του μοντέλου \textbf{{\en {Latent Dirichlet Allocation (LDA)}}}. 
Το {\en {LDA}} είναι ένα γενετικό πιθανοτικό μοντέλο ενός σώματος. 
Η βασική ιδέα είναι ότι τα κείμενα αντιπροσωπεύονται από τυχαίες προσμείξεις κρυφών θεμάτων, 
όπου κάθε θέμα χαρακτηρίζεται από μία κατανομή ως προς τις λέξεις. 
Τα {\en {pLSI}} και {\en {LDA}} μοντέλα είναι παρόμοια, με το {\en {LDA}} να αποτελεί την \textit{{\en {Bayesian}}} εκδοχή του {\en {pLSI}}.
Το μοντέλο αυτό θα αναλυθεί περαιτέρω στο Κεφάλαιο 2 όπου και θα χρησιμοποιηθεί. 
